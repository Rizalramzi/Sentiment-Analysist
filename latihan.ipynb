{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'komentar' : [\"keren sekali\",\n",
    "                                   \"mantap sekali\",\n",
    "                                   \"uhuy sekali\",\n",
    "                                   \"uhuy sekali\",\n",
    "                                   \"uhuy sekali\"],\n",
    "                     'label' : [\"0\",\n",
    "                                \"0\",\n",
    "                                \"0\",\n",
    "                                \"0\",\n",
    "                                \"0\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.91976759 0.39246348 0.         0.        ]\n",
      " [0.         0.39246348 0.91976759 0.        ]\n",
      " [0.         0.5557582  0.         0.83134399]\n",
      " [0.         0.5557582  0.         0.83134399]\n",
      " [0.         0.5557582  0.         0.83134399]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CustomTfidfVectorizer:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.idf = {}\n",
    "        self.doc_count = 0\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        doc_term_freqs = []\n",
    "        for doc in corpus:\n",
    "            term_freqs = {}\n",
    "            for term in doc.split():\n",
    "                if term in term_freqs:\n",
    "                    term_freqs[term] += 1\n",
    "                else:\n",
    "                    term_freqs[term] = 1\n",
    "            doc_term_freqs.append(term_freqs)\n",
    "            self.doc_count += 1\n",
    "\n",
    "            for term in term_freqs:\n",
    "                if term not in self.vocab:\n",
    "                    self.vocab[term] = len(self.vocab)\n",
    "\n",
    "        for term in self.vocab:\n",
    "            doc_freq = sum(1 for doc in doc_term_freqs if term in doc)\n",
    "            self.idf[term] = np.log(self.doc_count / (doc_freq + 1)) + 1  # Add 1 to avoid division by zero\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        values = []\n",
    "\n",
    "        for i, doc in enumerate(corpus):\n",
    "            term_freqs = {}\n",
    "            for term in doc.split():\n",
    "                if term in term_freqs:\n",
    "                    term_freqs[term] += 1\n",
    "                else:\n",
    "                    term_freqs[term] = 1\n",
    "            doc_length = sum(term_freqs.values())\n",
    "\n",
    "            for term, freq in term_freqs.items():\n",
    "                if term in self.vocab:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.vocab[term])\n",
    "                    tfidf = (freq / doc_length) * self.idf[term]\n",
    "                    values.append(tfidf)\n",
    "\n",
    "        matrix = np.zeros((len(corpus), len(self.vocab)))\n",
    "        for row, col, value in zip(rows, cols, values):\n",
    "            matrix[row, col] = value\n",
    "        return matrix / np.linalg.norm(matrix, axis=1, keepdims=True)  # Normalize rows to unit Euclidean length\n",
    "\n",
    "# Usage\n",
    "documents = data['komentar']\n",
    "vectorizer = CustomTfidfVectorizer()\n",
    "vectorizer.fit(documents)\n",
    "tfidf_matrix = vectorizer.transform(documents)\n",
    "print(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9197675884009774\n"
     ]
    }
   ],
   "source": [
    "min = np.min(tfidf_matrix)\n",
    "max = np.max(tfidf_matrix)\n",
    "print(min)\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNNClassifier:\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "\n",
    "        y_pred = []\n",
    "        for x in X_test:\n",
    "            distances = np.sqrt(np.sum((self.X_train - x) ** 2))\n",
    "            nearest_neighbors = np.argsort(distances)[:self.k]\n",
    "            nearest_labes = self.y_train[nearest_neighbors]\n",
    "            unique_labels, counts = np.unique(nearest_labes, return_counts=True)\n",
    "            predicted_labels = unique_labels[np.argmax(counts)]\n",
    "            y_pred.append(predicted_labels)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(x))\n",
    "    split_index = int(len(x) * (1 - test_size))\n",
    "    return x[indices[:split_index]], x[indices[split_index:]], y.iloc[indices[:split_index]], y.iloc[indices[split_index:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNNClassifier(k=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
